{
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Reinforcement Learning (RL)"
  },
  "Large Language Models (LLMs)<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 2,
    "update_time": 1765218772,
    "_id": "Large Language Models (LLMs)<SEP>Reinforcement Learning (RL)"
  },
  "Mathematics<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Mathematics<SEP>Reinforcement Learning (RL)"
  },
  "Coding<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Coding<SEP>Reinforcement Learning (RL)"
  },
  "Large Reasoning Models (LRMs)<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Large Reasoning Models (LRMs)<SEP>Reinforcement Learning (RL)"
  },
  "Computational Resources<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Computational Resources<SEP>Reinforcement Learning (RL)"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Large Reasoning Models (LRMs)"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Foundational Components": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Foundational Components"
  },
  "Algorithm Design<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Algorithm Design<SEP>Reinforcement Learning (RL)"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Foundational Problems": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Foundational Problems"
  },
  "Reinforcement Learning (RL)<SEP>Training Data": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Reinforcement Learning (RL)<SEP>Training Data"
  },
  "Infrastructure<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Infrastructure<SEP>Reinforcement Learning (RL)"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Training Resources"
  },
  "Foundational Components<SEP>Section 3": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Foundational Components<SEP>Section 3"
  },
  "Artificial SuperIntelligence (ASI)<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Artificial SuperIntelligence (ASI)<SEP>Reinforcement Learning (RL)"
  },
  "Foundational Problems<SEP>Section 4": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218605,
    "update_time": 1765218605,
    "_id": "Foundational Problems<SEP>Section 4"
  },
  "Section 5<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Section 5<SEP>Training Resources"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Applications": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Applications"
  },
  "Foundational Components<SEP>RL's Role": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Foundational Components<SEP>RL's Role"
  },
  "DeepSeek-R1<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "DeepSeek-R1<SEP>Reinforcement Learning (RL)"
  },
  "Applications<SEP>Section 6": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Applications<SEP>Section 6"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Abstract": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Abstract"
  },
  "Foundational Problems<SEP>RL vs. SFT": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Foundational Problems<SEP>RL vs. SFT"
  },
  "Foundational Components<SEP>Model Prior": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Foundational Components<SEP>Model Prior"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Figure 1": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Figure 1"
  },
  "Static Corpus Training<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Static Corpus Training<SEP>Training Resources"
  },
  "Foundational Problems<SEP>Reward Type": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Foundational Problems<SEP>Reward Type"
  },
  "Applications<SEP>Policy Optimization": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Applications<SEP>Policy Optimization"
  },
  "Foundational Components<SEP>Training Recipes": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Foundational Components<SEP>Training Recipes"
  },
  "Applications<SEP>Math Code": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Applications<SEP>Math Code"
  },
  "Dynamic Environment<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 2,
    "update_time": 1765218641,
    "_id": "Dynamic Environment<SEP>Training Resources"
  },
  "Foundational Problems<SEP>Reward Design": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Foundational Problems<SEP>Reward Design"
  },
  "Policy Critic-Based Algorithms<SEP>Policy Optimization": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Policy Critic-Based Algorithms<SEP>Policy Optimization"
  },
  "Applications<SEP>RL Infrastructure & Frameworks": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Applications<SEP>RL Infrastructure & Frameworks"
  },
  "Critic-Free Algorithms<SEP>Policy Optimization": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 2,
    "update_time": 1765218641,
    "_id": "Critic-Free Algorithms<SEP>Policy Optimization"
  },
  "Policy Critic-Based Algorithms<SEP>Policy Gradient Algorithms": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Policy Critic-Based Algorithms<SEP>Policy Gradient Algorithms"
  },
  "Agentic Tasks<SEP>Applications": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-d8e725479a22750b3ff1aef7d1040743"
    ],
    "count": 2,
    "update_time": 1765218641,
    "_id": "Agentic Tasks<SEP>Applications"
  },
  "Critic-Free Algorithms<SEP>Off-Policy Regularization": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Critic-Free Algorithms<SEP>Off-Policy Regularization"
  },
  "Dynamic Sampling<SEP>Sampling Strategy": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Dynamic Sampling<SEP>Sampling Strategy"
  },
  "Applications<SEP>Coding Tasks": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029",
      "chunk-d8e725479a22750b3ff1aef7d1040743"
    ],
    "count": 3,
    "update_time": 1765218641,
    "_id": "Applications<SEP>Coding Tasks"
  },
  "Multi-Agent Sampling<SEP>Sampling Strategy": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Multi-Agent Sampling<SEP>Sampling Strategy"
  },
  "Applications<SEP>Multimodal Robotics Tasks": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Applications<SEP>Multimodal Robotics Tasks"
  },
  "Critic-Free Algorithms<SEP>Optimization Objectives": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Critic-Free Algorithms<SEP>Optimization Objectives"
  },
  "Math Code<SEP>STEM Agent": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Math Code<SEP>STEM Agent"
  },
  "Sampling Hyper-Parameters<SEP>Sampling Strategy": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 2,
    "update_time": 1765218641,
    "_id": "Sampling Hyper-Parameters<SEP>Sampling Strategy"
  },
  "Applications<SEP>Medical Systems Tasks": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Applications<SEP>Medical Systems Tasks"
  },
  "Math Code<SEP>Mixture": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Math Code<SEP>Mixture"
  },
  "OpenRLHF<SEP>RL Infrastructure & Frameworks": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "OpenRLHF<SEP>RL Infrastructure & Frameworks"
  },
  "Compute<SEP>Sampling Strategy": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Compute<SEP>Sampling Strategy"
  },
  "Game<SEP>Math Code": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Game<SEP>Math Code"
  },
  "RL Infrastructure & Frameworks<SEP>veRL": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "RL Infrastructure & Frameworks<SEP>veRL"
  },
  "Math Code<SEP>Model Ensemble": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Math Code<SEP>Model Ensemble"
  },
  "Agent<SEP>Environment": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 2,
    "update_time": 1765218860,
    "_id": "Agent<SEP>Environment"
  },
  "Critic-Free Algorithms<SEP>Sampling Strategy": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Critic-Free Algorithms<SEP>Sampling Strategy"
  },
  "AReaL<SEP>RL Infrastructure & Frameworks": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "AReaL<SEP>RL Infrastructure & Frameworks"
  },
  "Environment<SEP>Reward": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 2,
    "update_time": 1765218907,
    "_id": "Environment<SEP>Reward"
  },
  "Action<SEP>Agent": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a",
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 2,
    "update_time": 1765218907,
    "_id": "Action<SEP>Agent"
  },
  "RL Infrastructure & Frameworks<SEP>slime": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "RL Infrastructure & Frameworks<SEP>slime"
  },
  "Environment<SEP>Interaction (Episode)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Environment<SEP>Interaction (Episode)"
  },
  "RL Infrastructure & Frameworks<SEP>TRL": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "RL Infrastructure & Frameworks<SEP>TRL"
  },
  "Reward Design<SEP>Sharpening Discovery": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Reward Design<SEP>Sharpening Discovery"
  },
  "Agent<SEP>Reward": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Agent<SEP>Reward"
  },
  "Training Recipes<SEP>Tricks Traps": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Training Recipes<SEP>Tricks Traps"
  },
  "Reward Design<SEP>Weak Strong": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Reward Design<SEP>Weak Strong"
  },
  "Process Outcome<SEP>Reward Type": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Process Outcome<SEP>Reward Type"
  },
  "Interaction (Episode)<SEP>Reward": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Interaction (Episode)<SEP>Reward"
  },
  "Generalize Memorize<SEP>Training Recipes": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Generalize Memorize<SEP>Training Recipes"
  },
  "Reward Type<SEP>Verifiable Generative Rewards": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Reward Type<SEP>Verifiable Generative Rewards"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Kaiyan Zhang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Kaiyan Zhang"
  },
  "Action<SEP>Interaction (Episode)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218606,
    "update_time": 1765218606,
    "_id": "Action<SEP>Interaction (Episode)"
  },
  "Kaiyan Zhang<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Kaiyan Zhang<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yuxin Zuo": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yuxin Zuo"
  },
  "Agent<SEP>Interaction (Episode)": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Agent<SEP>Interaction (Episode)"
  },
  "Reward Type<SEP>Unsupervised Rewards": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Reward Type<SEP>Unsupervised Rewards"
  },
  "Tsinghua University<SEP>Yuxin Zuo": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Tsinghua University<SEP>Yuxin Zuo"
  },
  "Reward Type<SEP>Shaping Rewards": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Reward Type<SEP>Shaping Rewards"
  },
  "Bingxiang He<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Bingxiang He<SEP>Tsinghua University"
  },
  "Tsinghua University<SEP>Youbang Sun": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Tsinghua University<SEP>Youbang Sun"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Bingxiang He": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Bingxiang He"
  },
  "Shanghai AI Laboratory<SEP>Yuchen Fan": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai AI Laboratory<SEP>Yuchen Fan"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Youbang Sun": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Youbang Sun"
  },
  "Runze Liu<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Runze Liu<SEP>Tsinghua University"
  },
  "Shanghai Jiao Tong University<SEP>Yuchen Fan": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai Jiao Tong University<SEP>Yuchen Fan"
  },
  "Che Jiang<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Che Jiang<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Runze Liu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Runze Liu"
  },
  "Kai Tian<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Kai Tian<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Che Jiang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Che Jiang"
  },
  "Pengfei Li<SEP>Shanghai AI Laboratory": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Pengfei Li<SEP>Shanghai AI Laboratory"
  },
  "Guoli Jia<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Guoli Jia<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yuchen Fan": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yuchen Fan"
  },
  "Harbin Institute of Technology<SEP>Pengfei Li": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Harbin Institute of Technology<SEP>Pengfei Li"
  },
  "University College London<SEP>Yu Fu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "University College London<SEP>Yu Fu"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Kai Tian": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Kai Tian"
  },
  "Tsinghua University<SEP>Xingtai Lv": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Tsinghua University<SEP>Xingtai Lv"
  },
  "Shanghai AI Laboratory<SEP>Yuchen Zhang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai AI Laboratory<SEP>Yuchen Zhang"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Guoli Jia": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Guoli Jia"
  },
  "Peking University<SEP>Yuchen Zhang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Peking University<SEP>Yuchen Zhang"
  },
  "Sihang Zeng<SEP>University of Washington": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Sihang Zeng<SEP>University of Washington"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Pengfei Li": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Pengfei Li"
  },
  "Shang Qu<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shang Qu<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yu Fu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yu Fu"
  },
  "Shang Qu<SEP>Shanghai AI Laboratory": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shang Qu<SEP>Shanghai AI Laboratory"
  },
  "Haozhan Li<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Haozhan Li<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xingtai Lv": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xingtai Lv"
  },
  "Shanghai AI Laboratory<SEP>Shijie Wang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai AI Laboratory<SEP>Shijie Wang"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yuchen Zhang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yuchen Zhang"
  },
  "Tsinghua University<SEP>Yuru Wang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Tsinghua University<SEP>Yuru Wang"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Sihang Zeng": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Sihang Zeng"
  },
  "Tsinghua University<SEP>Xinwei Long": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Tsinghua University<SEP>Xinwei Long"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Shang Qu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Shang Qu"
  },
  "Fangfu Liu<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Fangfu Liu<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Haozhan Li": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Haozhan Li"
  },
  "University of Science and Technology of China<SEP>Xiang Xu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "University of Science and Technology of China<SEP>Xiang Xu"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Shijie Wang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Shijie Wang"
  },
  "Jiaze Ma<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Jiaze Ma<SEP>Tsinghua University"
  },
  "Shanghai Jiao Tong University<SEP>Xuekai Zhu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai Jiao Tong University<SEP>Xuekai Zhu"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yuru Wang": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yuru Wang"
  },
  "Ermo Hua<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Ermo Hua<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xinwei Long": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xinwei Long"
  },
  "Ermo Hua<SEP>Shanghai AI Laboratory": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Ermo Hua<SEP>Shanghai AI Laboratory"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Fangfu Liu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Fangfu Liu"
  },
  "Tsinghua University<SEP>Yihao Liu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Tsinghua University<SEP>Yihao Liu"
  },
  "Shanghai AI Laboratory<SEP>Yihao Liu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai AI Laboratory<SEP>Yihao Liu"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xiang Xu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xiang Xu"
  },
  "Shanghai AI Laboratory<SEP>Zonglin Li": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai AI Laboratory<SEP>Zonglin Li"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Jiaze Ma": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Jiaze Ma"
  },
  "Huayu Chen<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Huayu Chen<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xuekai Zhu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xuekai Zhu"
  },
  "Shanghai AI Laboratory<SEP>Xiaoye Qu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai AI Laboratory<SEP>Xiaoye Qu"
  },
  "Shanghai AI Laboratory<SEP>Yafu Li": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Shanghai AI Laboratory<SEP>Yafu Li"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Ermo Hua": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Ermo Hua"
  },
  "Tsinghua University<SEP>Weize Chen": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218607,
    "update_time": 1765218607,
    "_id": "Tsinghua University<SEP>Weize Chen"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yihao Liu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yihao Liu"
  },
  "Tsinghua University<SEP>Zhenzhao Yuan": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Tsinghua University<SEP>Zhenzhao Yuan"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Zonglin Li": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Zonglin Li"
  },
  "Harbin Institute of Technology<SEP>Junqi Gao": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Harbin Institute of Technology<SEP>Junqi Gao"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Huayu Chen": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Huayu Chen"
  },
  "Dong Li<SEP>Harbin Institute of Technology": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Dong Li<SEP>Harbin Institute of Technology"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xiaoye Qu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Xiaoye Qu"
  },
  "Huazhong University of Science and Technology<SEP>Zhiyuan Ma": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Huazhong University of Science and Technology<SEP>Zhiyuan Ma"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yafu Li": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Yafu Li"
  },
  "Ganqu Cui<SEP>Shanghai AI Laboratory": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Ganqu Cui<SEP>Shanghai AI Laboratory"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Weize Chen": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Weize Chen"
  },
  "Tsinghua University<SEP>Zhiyuan Liu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Tsinghua University<SEP>Zhiyuan Liu"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Zhenzhao Yuan": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Zhenzhao Yuan"
  },
  "Biqing Qi<SEP>Shanghai AI Laboratory": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Biqing Qi<SEP>Shanghai AI Laboratory"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Junqi Gao": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Junqi Gao"
  },
  "Ning Ding<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Ning Ding<SEP>Tsinghua University"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Dong Li": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Dong Li"
  },
  "Ning Ding<SEP>Shanghai AI Laboratory": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Ning Ding<SEP>Shanghai AI Laboratory"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Zhiyuan Ma": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Zhiyuan Ma"
  },
  "Bowen Zhou<SEP>Tsinghua University": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Bowen Zhou<SEP>Tsinghua University"
  },
  "Bowen Zhou<SEP>Shanghai AI Laboratory": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "Bowen Zhou<SEP>Shanghai AI Laboratory"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Ganqu Cui": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Ganqu Cui"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Zhiyuan Liu": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Zhiyuan Liu"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Biqing Qi": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Biqing Qi"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Ning Ding": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Ning Ding"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Bowen Zhou": {
    "chunk_ids": [
      "chunk-32bcdbba2d266d061d85f94faf74b18a"
    ],
    "count": 1,
    "create_time": 1765218608,
    "update_time": 1765218608,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Bowen Zhou"
  },
  "Background<SEP>Preliminaries": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Background<SEP>Preliminaries"
  },
  "Foundational Components<SEP>Reward Design": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Foundational Components<SEP>Reward Design"
  },
  "Frontier Models<SEP>Preliminaries": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Frontier Models<SEP>Preliminaries"
  },
  "Reward Design<SEP>Verifiable Rewards": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Reward Design<SEP>Verifiable Rewards"
  },
  "Foundational Components<SEP>Policy Optimization": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Foundational Components<SEP>Policy Optimization"
  },
  "Preliminaries<SEP>Related Surveys": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Preliminaries<SEP>Related Surveys"
  },
  "Foundational Components<SEP>Sampling Strategy": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Foundational Components<SEP>Sampling Strategy"
  },
  "Policy Gradient Objective<SEP>Policy Optimization": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Policy Gradient Objective<SEP>Policy Optimization"
  },
  "Generative Rewards<SEP>Reward Design": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Generative Rewards<SEP>Reward Design"
  },
  "Critic-Based Algorithms<SEP>Policy Optimization": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Critic-Based Algorithms<SEP>Policy Optimization"
  },
  "Dense Rewards<SEP>Reward Design": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Dense Rewards<SEP>Reward Design"
  },
  "Dynamic And Structured Sampling<SEP>Sampling Strategy": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Dynamic And Structured Sampling<SEP>Sampling Strategy"
  },
  "Reward Design<SEP>Unsupervised Rewards": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Reward Design<SEP>Unsupervised Rewards"
  },
  "Foundational Problems<SEP>RL's Role: Sharpening Or Discovery": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Foundational Problems<SEP>RL's Role: Sharpening Or Discovery"
  },
  "Off-Policy Optimization<SEP>Policy Optimization": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Off-Policy Optimization<SEP>Policy Optimization"
  },
  "Foundational Problems<SEP>RL Vs. SFT: Generalize Or Memorize": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Foundational Problems<SEP>RL Vs. SFT: Generalize Or Memorize"
  },
  "Reward Design<SEP>Rewards Shaping": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Reward Design<SEP>Rewards Shaping"
  },
  "Static Corpus<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Static Corpus<SEP>Training Resources"
  },
  "Policy Optimization<SEP>Regularization Objectives": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Policy Optimization<SEP>Regularization Objectives"
  },
  "Foundational Problems<SEP>Model Prior: Weak And Strong": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Foundational Problems<SEP>Model Prior: Weak And Strong"
  },
  "Foundational Problems<SEP>Training Recipes: Tricks Or Traps": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Foundational Problems<SEP>Training Recipes: Tricks Or Traps"
  },
  "RL Infrastructure<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "RL Infrastructure<SEP>Training Resources"
  },
  "Coding Tasks<SEP>Page 47": {
    "chunk_ids": [
      "chunk-d8e725479a22750b3ff1aef7d1040743"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Coding Tasks<SEP>Page 47"
  },
  "Foundational Problems<SEP>Reward Type: Process Or Outcome": {
    "chunk_ids": [
      "chunk-7f8d14eb8cca7addf208d3ebd7dc7029"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Foundational Problems<SEP>Reward Type: Process Or Outcome"
  },
  "Applications<SEP>Multimodal Tasks": {
    "chunk_ids": [
      "chunk-d8e725479a22750b3ff1aef7d1040743"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Applications<SEP>Multimodal Tasks"
  },
  "Agentic Tasks<SEP>Page 49": {
    "chunk_ids": [
      "chunk-d8e725479a22750b3ff1aef7d1040743"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Agentic Tasks<SEP>Page 49"
  },
  "Page 43<SEP>RL Infrastructure": {
    "chunk_ids": [
      "chunk-d8e725479a22750b3ff1aef7d1040743"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Page 43<SEP>RL Infrastructure"
  },
  "Multimodal Tasks<SEP>Page 52": {
    "chunk_ids": [
      "chunk-d8e725479a22750b3ff1aef7d1040743"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Multimodal Tasks<SEP>Page 52"
  },
  "Applications<SEP>Page 46": {
    "chunk_ids": [
      "chunk-d8e725479a22750b3ff1aef7d1040743"
    ],
    "count": 1,
    "create_time": 1765218641,
    "update_time": 1765218641,
    "_id": "Applications<SEP>Page 46"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f",
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 2,
    "update_time": 1765219166,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Reinforcement Learning"
  },
  "Continual RL for LLMs<SEP>Future Directions": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Continual RL for LLMs<SEP>Future Directions"
  },
  "Future Directions<SEP>Memory-based RL for LLMs": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Future Directions<SEP>Memory-based RL for LLMs"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Large Reasoning Models": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f",
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f",
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 3,
    "update_time": 1765219166,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Large Reasoning Models"
  },
  "Future Directions<SEP>Model-based RL for LLMs": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Future Directions<SEP>Model-based RL for LLMs"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Multi-Agent Systems": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Multi-Agent Systems"
  },
  "Future Directions<SEP>Teaching LRMs Efficient Reasoning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Future Directions<SEP>Teaching LRMs Efficient Reasoning"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Robotics Tasks": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Robotics Tasks"
  },
  "Future Directions<SEP>Teaching LLMs Latent Space Reasoning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Future Directions<SEP>Teaching LLMs Latent Space Reasoning"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Medical Tasks": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Medical Tasks"
  },
  "Future Directions<SEP>RL for LLMs Pre-training": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Future Directions<SEP>RL for LLMs Pre-training"
  },
  "Continual RL for LLMs<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Continual RL for LLMs<SEP>Reinforcement Learning"
  },
  "Future Directions<SEP>RL for Diffusion-based LLMs": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Future Directions<SEP>RL for Diffusion-based LLMs"
  },
  "Continual RL for LLMs<SEP>Large Language Models": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Continual RL for LLMs<SEP>Large Language Models"
  },
  "Memory-based RL for LLMs<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218685,
    "update_time": 1765218685,
    "_id": "Memory-based RL for LLMs<SEP>Reinforcement Learning"
  },
  "Future Directions<SEP>RL for LLMs in Scientific Discovery": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Future Directions<SEP>RL for LLMs in Scientific Discovery"
  },
  "Model-based RL for LLMs<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Model-based RL for LLMs<SEP>Reinforcement Learning"
  },
  "Large Language Models<SEP>Memory-based RL for LLMs": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Large Language Models<SEP>Memory-based RL for LLMs"
  },
  "Future Directions<SEP>RL for Architecture-Algorithm Co-Design": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Future Directions<SEP>RL for Architecture-Algorithm Co-Design"
  },
  "Large Reasoning Models<SEP>Teaching LRMs Efficient Reasoning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Large Reasoning Models<SEP>Teaching LRMs Efficient Reasoning"
  },
  "Large Language Models<SEP>Model-based RL for LLMs": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Large Language Models<SEP>Model-based RL for LLMs"
  },
  "RL for LLMs Pre-training<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "RL for LLMs Pre-training<SEP>Reinforcement Learning"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Future Directions": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Future Directions"
  },
  "Large Language Models<SEP>Teaching LLMs Latent Space Reasoning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Large Language Models<SEP>Teaching LLMs Latent Space Reasoning"
  },
  "RL for Diffusion-based LLMs<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "RL for Diffusion-based LLMs<SEP>Reinforcement Learning"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Conclusion": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Conclusion"
  },
  "Large Language Models<SEP>RL for LLMs Pre-training": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Large Language Models<SEP>RL for LLMs Pre-training"
  },
  "RL for LLMs in Scientific Discovery<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "RL for LLMs in Scientific Discovery<SEP>Reinforcement Learning"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Author Contributions": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Author Contributions"
  },
  "Large Language Models<SEP>RL for Diffusion-based LLMs": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Large Language Models<SEP>RL for Diffusion-based LLMs"
  },
  "RL for Architecture-Algorithm Co-Design<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "RL for Architecture-Algorithm Co-Design<SEP>Reinforcement Learning"
  },
  "Large Language Models<SEP>RL for LLMs in Scientific Discovery": {
    "chunk_ids": [
      "chunk-0f35d639cf51f0ab7d4017f06d35581f"
    ],
    "count": 1,
    "create_time": 1765218686,
    "update_time": 1765218686,
    "_id": "Large Language Models<SEP>RL for LLMs in Scientific Discovery"
  },
  "Reinforcement Learning (RL)<SEP>Sutton et al., 1998": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Reinforcement Learning (RL)<SEP>Sutton et al., 1998"
  },
  "Artificial Agents<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Artificial Agents<SEP>Reinforcement Learning (RL)"
  },
  "AlphaGo<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaGo<SEP>Reinforcement Learning (RL)"
  },
  "AlphaZero<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Reinforcement Learning (RL)"
  },
  "AlphaGo<SEP>Silver et al., 2016": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaGo<SEP>Silver et al., 2016"
  },
  "AlphaGo<SEP>Go": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaGo<SEP>Go"
  },
  "AlphaZero<SEP>Silver et al., 2017": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Silver et al., 2017"
  },
  "AlphaZero<SEP>Go": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Go"
  },
  "AlphaZero<SEP>Chess": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Chess"
  },
  "Large Language Models (LLMs)<SEP>Zhao et al., 2023a": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Large Language Models (LLMs)<SEP>Zhao et al., 2023a"
  },
  "Human Alignment<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Human Alignment<SEP>Reinforcement Learning (RL)"
  },
  "Human Alignment<SEP>Ouyang et al., 2022": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Human Alignment<SEP>Ouyang et al., 2022"
  },
  "AlphaZero<SEP>Shogi": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Shogi"
  },
  "Christiano et al., 2017<SEP>Reinforcement Learning from Human Feedback (RLHF)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Christiano et al., 2017<SEP>Reinforcement Learning from Human Feedback (RLHF)"
  },
  "Human Alignment<SEP>Reinforcement Learning from Human Feedback (RLHF)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Human Alignment<SEP>Reinforcement Learning from Human Feedback (RLHF)"
  },
  "AlphaZero<SEP>Stratego": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Stratego"
  },
  "Helpfulness, Honesty, and Harmlessness (3H)<SEP>Reinforcement Learning from Human Feedback (RLHF)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Helpfulness, Honesty, and Harmlessness (3H)<SEP>Reinforcement Learning from Human Feedback (RLHF)"
  },
  "Direct Preference Optimization (DPO)<SEP>Human Alignment": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Direct Preference Optimization (DPO)<SEP>Human Alignment"
  },
  "AlphaZero<SEP>Perolat et al., 2022": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Perolat et al., 2022"
  },
  "Direct Preference Optimization (DPO)<SEP>Rafailov et al., 2023": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Direct Preference Optimization (DPO)<SEP>Rafailov et al., 2023"
  },
  "RL for Large Reasoning Models (LRMs)<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "RL for Large Reasoning Models (LRMs)<SEP>Reinforcement Learning (RL)"
  },
  "AlphaZero<SEP>Schrittwieser et al., 2020": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Schrittwieser et al., 2020"
  },
  "Bai et al., 2022b<SEP>Helpfulness, Honesty, and Harmlessness (3H)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Bai et al., 2022b<SEP>Helpfulness, Honesty, and Harmlessness (3H)"
  },
  "RL for Large Reasoning Models (LRMs)<SEP>Xu et al., 2025a": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "RL for Large Reasoning Models (LRMs)<SEP>Xu et al., 2025a"
  },
  "AlphaZero<SEP>Silver et al., 2018": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "AlphaZero<SEP>Silver et al., 2018"
  },
  "Direct Preference Optimization (DPO)<SEP>Helpfulness, Honesty, and Harmlessness (3H)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Direct Preference Optimization (DPO)<SEP>Helpfulness, Honesty, and Harmlessness (3H)"
  },
  "Long-Form Reasoning<SEP>RL for Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Long-Form Reasoning<SEP>RL for Large Reasoning Models (LRMs)"
  },
  "OpenAI o1<SEP>RL for Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "OpenAI o1<SEP>RL for Large Reasoning Models (LRMs)"
  },
  "Long-Form Reasoning<SEP>Reinforcement Learning with Verifiable Rewards (RLVR)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Long-Form Reasoning<SEP>Reinforcement Learning with Verifiable Rewards (RLVR)"
  },
  "DeepSeek-R1<SEP>RL for Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "DeepSeek-R1<SEP>RL for Large Reasoning Models (LRMs)"
  },
  "Jaech et al., 2024<SEP>OpenAI o1": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Jaech et al., 2024<SEP>OpenAI o1"
  },
  "Answer Correctness for Mathematics<SEP>Reinforcement Learning with Verifiable Rewards (RLVR)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Answer Correctness for Mathematics<SEP>Reinforcement Learning with Verifiable Rewards (RLVR)"
  },
  "Long-Form Reasoning<SEP>Planning": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Long-Form Reasoning<SEP>Planning"
  },
  "Long-Form Reasoning<SEP>Reflection": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Long-Form Reasoning<SEP>Reflection"
  },
  "Reinforcement Learning with Verifiable Rewards (RLVR)<SEP>Unit-Test Pass Rates for Code": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "Reinforcement Learning with Verifiable Rewards (RLVR)<SEP>Unit-Test Pass Rates for Code"
  },
  "DeepSeek-R1<SEP>Guo et al., 2025a": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218772,
    "update_time": 1765218772,
    "_id": "DeepSeek-R1<SEP>Guo et al., 2025a"
  },
  "Long-Form Reasoning<SEP>Self-Correction": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Long-Form Reasoning<SEP>Self-Correction"
  },
  "Brown et al., 2024<SEP>Test-Time Compute": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Brown et al., 2024<SEP>Test-Time Compute"
  },
  "OpenAI o1<SEP>Reinforcement Learning with Verifiable Rewards (RLVR)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "OpenAI o1<SEP>Reinforcement Learning with Verifiable Rewards (RLVR)"
  },
  "Liu et al., 2025m<SEP>Test-Time Compute": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Liu et al., 2025m<SEP>Test-Time Compute"
  },
  "Pre-Training<SEP>Scaling Axis": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Pre-Training<SEP>Scaling Axis"
  },
  "DeepSeek-R1<SEP>Reinforcement Learning with Verifiable Rewards (RLVR)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "DeepSeek-R1<SEP>Reinforcement Learning with Verifiable Rewards (RLVR)"
  },
  "OpenAI o1<SEP>Train-Time Compute": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "OpenAI o1<SEP>Train-Time Compute"
  },
  "Snell et al., 2024<SEP>Test-Time Compute": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Snell et al., 2024<SEP>Test-Time Compute"
  },
  "DeepSeek-R1<SEP>Group Relative Policy Optimization (GRPO)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "DeepSeek-R1<SEP>Group Relative Policy Optimization (GRPO)"
  },
  "Aghajanyan et al., 2023<SEP>Scaling Axis": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Aghajanyan et al., 2023<SEP>Scaling Axis"
  },
  "OpenAI o1<SEP>Test-Time Compute": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "OpenAI o1<SEP>Test-Time Compute"
  },
  "OpenAI, 2025a,b<SEP>Reasoning": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "OpenAI, 2025a,b<SEP>Reasoning"
  },
  "Kaplan et al., 2020<SEP>Scaling Axis": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Kaplan et al., 2020<SEP>Scaling Axis"
  },
  "Large Reasoning Models (LRMs)<SEP>Test-Time Compute": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Large Reasoning Models (LRMs)<SEP>Test-Time Compute"
  },
  "Group Relative Policy Optimization (GRPO)<SEP>Reasoning": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Group Relative Policy Optimization (GRPO)<SEP>Reasoning"
  },
  "OpenAI o1<SEP>Scaling Axis": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "OpenAI o1<SEP>Scaling Axis"
  },
  "Reward Maximization Objective<SEP>Silver et al., 2021": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Reward Maximization Objective<SEP>Silver et al., 2021"
  },
  "Base Models<SEP>Group Relative Policy Optimization (GRPO)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Base Models<SEP>Group Relative Policy Optimization (GRPO)"
  },
  "Automatically Checkable Rewards<SEP>Competition Mathematics": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Automatically Checkable Rewards<SEP>Competition Mathematics"
  },
  "Competitive Programming<SEP>El-Kishky et al., 2025": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Competitive Programming<SEP>El-Kishky et al., 2025"
  },
  "Bai et al., 2025<SEP>Selected Scientific Domains": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Bai et al., 2025<SEP>Selected Scientific Domains"
  },
  "Chain-of-Thought<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Chain-of-Thought<SEP>Large Reasoning Models (LRMs)"
  },
  "Data Limitations<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Data Limitations<SEP>Reinforcement Learning (RL)"
  },
  "Automatically Checkable Rewards<SEP>Competitive Programming": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Automatically Checkable Rewards<SEP>Competitive Programming"
  },
  "Large Reasoning Models (LRMs)<SEP>Reward Maximization Objective": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Large Reasoning Models (LRMs)<SEP>Reward Maximization Objective"
  },
  "Chain-of-Thought<SEP>Wei et al., 2022": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Chain-of-Thought<SEP>Wei et al., 2022"
  },
  "Automatically Checkable Rewards<SEP>Selected Scientific Domains": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Automatically Checkable Rewards<SEP>Selected Scientific Domains"
  },
  "Self-Generated Training Data<SEP>Silver et al., 2018": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Self-Generated Training Data<SEP>Silver et al., 2018"
  },
  "Data Limitations<SEP>Shumailov et al., 2024": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Data Limitations<SEP>Shumailov et al., 2024"
  },
  "Computational Resources<SEP>RL for Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Computational Resources<SEP>RL for Large Reasoning Models (LRMs)"
  },
  "Reinforcement Learning (RL)<SEP>Self-Generated Training Data": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Reinforcement Learning (RL)<SEP>Self-Generated Training Data"
  },
  "Data Limitations<SEP>Villalobos et al., 2022": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Data Limitations<SEP>Villalobos et al., 2022"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Preliminary Definitions of RL Modeling": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Preliminary Definitions of RL Modeling"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Frontier Reasoning Models": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Frontier Reasoning Models"
  },
  "Algorithm Design<SEP>RL for Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Algorithm Design<SEP>RL for Large Reasoning Models (LRMs)"
  },
  "Artificial Superintelligence (ASI)<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Artificial Superintelligence (ASI)<SEP>Reinforcement Learning (RL)"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Foundational Components of RL for LRMs": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Foundational Components of RL for LRMs"
  },
  "Frontier Reasoning Models<SEP>OpenAI o1": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Frontier Reasoning Models<SEP>OpenAI o1"
  },
  "AlphaGo<SEP>Reward Feedback": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "AlphaGo<SEP>Reward Feedback"
  },
  "AlphaZero<SEP>Reward Feedback": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "AlphaZero<SEP>Reward Feedback"
  },
  "RL for Large Reasoning Models (LRMs)<SEP>Training Data": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "RL for Large Reasoning Models (LRMs)<SEP>Training Data"
  },
  "Reinforcement Learning with Verifiable Rewards (RLVR)<SEP>Verifiable Rewards": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Reinforcement Learning with Verifiable Rewards (RLVR)<SEP>Verifiable Rewards"
  },
  "DeepSeek-R1<SEP>Mathematics": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "DeepSeek-R1<SEP>Mathematics"
  },
  "Reinforcement Learning (RL)<SEP>Reward Signals": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Reinforcement Learning (RL)<SEP>Reward Signals"
  },
  "Coding Tasks<SEP>DeepSeek-R1": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Coding Tasks<SEP>DeepSeek-R1"
  },
  "Compute Budget<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Compute Budget<SEP>Large Reasoning Models (LRMs)"
  },
  "Infrastructure<SEP>RL for Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "Infrastructure<SEP>RL for Large Reasoning Models (LRMs)"
  },
  "RL for Large Reasoning Models (LRMs)<SEP>Reasoning": {
    "chunk_ids": [
      "chunk-8b7f62b7202fa8bc4469bb44567df186"
    ],
    "count": 1,
    "create_time": 1765218773,
    "update_time": 1765218773,
    "_id": "RL for Large Reasoning Models (LRMs)<SEP>Reasoning"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002",
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 2,
    "update_time": 1765218907,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Reinforcement Learning (RL)"
  },
  "RLHF<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "RLHF<SEP>Reinforcement Learning (RL)"
  },
  "DPO<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "DPO<SEP>Reinforcement Learning (RL)"
  },
  "Human Alignment<SEP>RLHF": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Human Alignment<SEP>RLHF"
  },
  "RLVR<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "RLVR<SEP>Reinforcement Learning (RL)"
  },
  "DPO<SEP>Human Alignment": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "DPO<SEP>Human Alignment"
  },
  "Open-Ended RL<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Open-Ended RL<SEP>Reinforcement Learning (RL)"
  },
  "Large Reasoning Models (LRMs)<SEP>RLVR": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Large Reasoning Models (LRMs)<SEP>RLVR"
  },
  "Complex Task Solving<SEP>RLVR": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Complex Task Solving<SEP>RLVR"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Large Reasoning Models (LRMs)"
  },
  "Policy Optimization<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Policy Optimization<SEP>Reinforcement Learning (RL)"
  },
  "Large Language Models (LLMs)<SEP>Open-Ended RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Large Language Models (LLMs)<SEP>Open-Ended RL"
  },
  "Static Corpora<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Static Corpora<SEP>Training Resources"
  },
  "Reinforcement Learning (RL)<SEP>Sampling Strategies": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Reinforcement Learning (RL)<SEP>Sampling Strategies"
  },
  "Dynamic Environments<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Dynamic Environments<SEP>Training Resources"
  },
  "Reinforcement Learning (RL)<SEP>Supervised Fine-Tuning (SFT)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Reinforcement Learning (RL)<SEP>Supervised Fine-Tuning (SFT)"
  },
  "Training Infrastructure<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Training Infrastructure<SEP>Training Resources"
  },
  "Model Priors<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Model Priors<SEP>Reinforcement Learning (RL)"
  },
  "Reinforcement Learning (RL)<SEP>Training Recipes": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Reinforcement Learning (RL)<SEP>Training Recipes"
  },
  "Reinforcement Learning (RL)<SEP>Reward Definitions": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Reinforcement Learning (RL)<SEP>Reward Definitions"
  },
  "Reinforcement Learning (RL)<SEP>Training Resources": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Reinforcement Learning (RL)<SEP>Training Resources"
  },
  "Coding Tasks<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Coding Tasks<SEP>Reinforcement Learning (RL)"
  },
  "Agentic Tasks<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Agentic Tasks<SEP>Reinforcement Learning (RL)"
  },
  "Multimodal Tasks<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Multimodal Tasks<SEP>Reinforcement Learning (RL)"
  },
  "Multi-Agent Systems<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Multi-Agent Systems<SEP>Reinforcement Learning (RL)"
  },
  "Reinforcement Learning (RL)<SEP>Robotics Tasks": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Reinforcement Learning (RL)<SEP>Robotics Tasks"
  },
  "GPT-3.5<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "GPT-3.5<SEP>Large Reasoning Models (LRMs)"
  },
  "GPT-4<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "GPT-4<SEP>Large Reasoning Models (LRMs)"
  },
  "Medical Applications<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Medical Applications<SEP>Reinforcement Learning (RL)"
  },
  "Large Reasoning Models (LRMs)<SEP>Llama 3": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Large Reasoning Models (LRMs)<SEP>Llama 3"
  },
  "Agent<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002",
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 2,
    "update_time": 1765218907,
    "_id": "Agent<SEP>Reinforcement Learning (RL)"
  },
  "Large Reasoning Models (LRMs)<SEP>Qwen 2.5": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Large Reasoning Models (LRMs)<SEP>Qwen 2.5"
  },
  "Markov Decision Process<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218860,
    "update_time": 1765218860,
    "_id": "Markov Decision Process<SEP>Reinforcement Learning (RL)"
  },
  "Large Reasoning Models (LRMs)<SEP>O1": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Large Reasoning Models (LRMs)<SEP>O1"
  },
  "RL From Human Direct Preference<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "RL From Human Direct Preference<SEP>Reinforcement Learning (RL)"
  },
  "Actions<SEP>Agent": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Actions<SEP>Agent"
  },
  "DeepSeek-R1<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "DeepSeek-R1<SEP>Large Reasoning Models (LRMs)"
  },
  "Agent<SEP>Cumulative Reward": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Agent<SEP>Cumulative Reward"
  },
  "RL With Verifiable Feedback Optimization Reward<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "RL With Verifiable Feedback Optimization Reward<SEP>Reinforcement Learning (RL)"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Research Directions": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Research Directions"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Technical Approaches": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Technical Approaches"
  },
  "Reinforcement Learning (RL)<SEP>Reward-Based RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Reward-Based RL"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Foundational Problems": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Foundational Problems"
  },
  "Reinforcement Learning (RL)<SEP>Reward-Free RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Reward-Free RL"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Controversial Problems": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Controversial Problems"
  },
  "Reinforcement Learning (RL)<SEP>Rule-Based RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Rule-Based RL"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Role of RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Role of RL"
  },
  "Reinforcement Learning (RL)<SEP>Sequential Decision Making": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Sequential Decision Making"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Scaling RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Scaling RL"
  },
  "Reinforcement Learning (RL)<SEP>Research Directions": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Research Directions"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Novel Algorithms": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Novel Algorithms"
  },
  "Reinforcement Learning (RL)<SEP>Technical Approaches": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Technical Approaches"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Mechanisms": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Mechanisms"
  },
  "Foundational Problems<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Foundational Problems<SEP>Reinforcement Learning (RL)"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Features": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Features"
  },
  "Controversial Problems<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Controversial Problems<SEP>Reinforcement Learning (RL)"
  },
  "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Research Avenues": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "ASurveyofReinforcementLearningforLargeReasoningModels<SEP>Research Avenues"
  },
  "Reinforcement Learning (RL)<SEP>Role of RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Role of RL"
  },
  "Large Language Models (LLMs)<SEP>Scaling RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Large Language Models (LLMs)<SEP>Scaling RL"
  },
  "Policy Optimization<SEP>Research Directions": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Policy Optimization<SEP>Research Directions"
  },
  "Reinforcement Learning (RL)<SEP>Scaling RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Scaling RL"
  },
  "Research Directions<SEP>Sampling Strategies": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Research Directions<SEP>Sampling Strategies"
  },
  "Policy Optimization<SEP>Technical Approaches": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Policy Optimization<SEP>Technical Approaches"
  },
  "Novel Algorithms<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Novel Algorithms<SEP>Reinforcement Learning (RL)"
  },
  "Foundational Problems<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Foundational Problems<SEP>Large Reasoning Models (LRMs)"
  },
  "Sampling Strategies<SEP>Technical Approaches": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Sampling Strategies<SEP>Technical Approaches"
  },
  "Controversial Problems<SEP>Large Reasoning Models (LRMs)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Controversial Problems<SEP>Large Reasoning Models (LRMs)"
  },
  "Mechanisms<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Mechanisms<SEP>Reinforcement Learning (RL)"
  },
  "Large Reasoning Models (LRMs)<SEP>Role of RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Large Reasoning Models (LRMs)<SEP>Role of RL"
  },
  "Features<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Features<SEP>Reinforcement Learning (RL)"
  },
  "Large Reasoning Models (LRMs)<SEP>Model Priors": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Large Reasoning Models (LRMs)<SEP>Model Priors"
  },
  "Reinforcement Learning (RL)<SEP>Research Avenues": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Reinforcement Learning (RL)<SEP>Research Avenues"
  },
  "Large Reasoning Models (LRMs)<SEP>Training Recipes": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Large Reasoning Models (LRMs)<SEP>Training Recipes"
  },
  "Large Reasoning Models (LRMs)<SEP>Reward Definitions": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Large Reasoning Models (LRMs)<SEP>Reward Definitions"
  },
  "Large Reasoning Models (LRMs)<SEP>Scaling RL": {
    "chunk_ids": [
      "chunk-8355cb8033a4afe3e01992fcee557002"
    ],
    "count": 1,
    "create_time": 1765218861,
    "update_time": 1765218861,
    "_id": "Large Reasoning Models (LRMs)<SEP>Scaling RL"
  },
  "Completion Tokens<SEP>Language Models (LMs)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Completion Tokens<SEP>Language Models (LMs)"
  },
  "Prompt/Task (x)<SEP>State": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Prompt/Task (x)<SEP>State"
  },
  "Environment<SEP>Reinforcement Learning (RL)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Environment<SEP>Reinforcement Learning (RL)"
  },
  "Response<SEP>Reward": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Response<SEP>Reward"
  },
  "Completion Tokens<SEP>State": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Completion Tokens<SEP>State"
  },
  "Markov Decision Process (MDP)<SEP>Sutton et al., 1998": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Markov Decision Process (MDP)<SEP>Sutton et al., 1998"
  },
  "Agent<SEP>Language Models (LMs)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Agent<SEP>Language Models (LMs)"
  },
  "Markov Decision Process (MDP)<SEP>State Space (S)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Markov Decision Process (MDP)<SEP>State Space (S)"
  },
  "Environment<SEP>State": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Environment<SEP>State"
  },
  "Action Space (A)<SEP>Markov Decision Process (MDP)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Action Space (A)<SEP>Markov Decision Process (MDP)"
  },
  "Agent<SEP>State": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Agent<SEP>State"
  },
  "Language Models (LMs)<SEP>Policy ()": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Language Models (LMs)<SEP>Policy ()"
  },
  "Markov Decision Process (MDP)<SEP>Transition Dynamics (P)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Markov Decision Process (MDP)<SEP>Transition Dynamics (P)"
  },
  "Data Distribution (D)<SEP>Prompt/Task (x)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Data Distribution (D)<SEP>Prompt/Task (x)"
  },
  "Policy ()<SEP>Sequence (y)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Policy ()<SEP>Sequence (y)"
  },
  "State<SEP>Token (a  V)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "State<SEP>Token (a  V)"
  },
  "Markov Decision Process (MDP)<SEP>Reward Function (R)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Markov Decision Process (MDP)<SEP>Reward Function (R)"
  },
  "State<SEP>Transition Dynamics (P)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "State<SEP>Transition Dynamics (P)"
  },
  "Action<SEP>Sequence (y)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Action<SEP>Sequence (y)"
  },
  "Agent<SEP>Policy ()": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Agent<SEP>Policy ()"
  },
  "EOS Token<SEP>Trajectory": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "EOS Token<SEP>Trajectory"
  },
  "Discount Factor ()<SEP>Markov Decision Process (MDP)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Discount Factor ()<SEP>Markov Decision Process (MDP)"
  },
  "Reward<SEP>Sequence (y)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Reward<SEP>Sequence (y)"
  },
  "Action<SEP>Token (a  V)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Action<SEP>Token (a  V)"
  },
  "Return (G)<SEP>Trajectory": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Return (G)<SEP>Trajectory"
  },
  "Action<SEP>Segment (y(k))": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Action<SEP>Segment (y(k))"
  },
  "Learning Objective<SEP>Return (G)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Learning Objective<SEP>Return (G)"
  },
  "Dataset D<SEP>Prompt/Task (x)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Dataset D<SEP>Prompt/Task (x)"
  },
  "Reward<SEP>Token (a  V)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218907,
    "update_time": 1765218907,
    "_id": "Reward<SEP>Token (a  V)"
  },
  "EOS Token<SEP>Terminal State": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "EOS Token<SEP>Terminal State"
  },
  "Reward<SEP>Segment (y(k))": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Reward<SEP>Segment (y(k))"
  },
  "Data Distribution (D)<SEP>Learning Objective": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Data Distribution (D)<SEP>Learning Objective"
  },
  "Large Language Models (LLMs)<SEP>Transition Dynamics (P)": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Large Language Models (LLMs)<SEP>Transition Dynamics (P)"
  },
  "Policy ()<SEP>Terminal State": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Policy ()<SEP>Terminal State"
  },
  "Action<SEP>Reward": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Action<SEP>Reward"
  },
  "Return (G)<SEP>Table 2": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Return (G)<SEP>Table 2"
  },
  "Data Distribution (D)<SEP>Dataset D": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Data Distribution (D)<SEP>Dataset D"
  },
  "Terminal State<SEP>Trajectory": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Terminal State<SEP>Trajectory"
  },
  "Action<SEP>Table 2": {
    "chunk_ids": [
      "chunk-42002d06ba2f88fbde0f4fdbf912a18f"
    ],
    "count": 1,
    "create_time": 1765218908,
    "update_time": 1765218908,
    "_id": "Action<SEP>Table 2"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e",
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 2,
    "update_time": 1765219262,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Reinforcement Learning"
  },
  "Learned Policy<SEP>Reference Policy": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219041,
    "update_time": 1765219041,
    "_id": "Learned Policy<SEP>Reference Policy"
  },
  "OpenAI<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219041,
    "update_time": 1765219041,
    "_id": "OpenAI<SEP>o1 Series"
  },
  "Jaechetal.,2024<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219041,
    "update_time": 1765219041,
    "_id": "Jaechetal.,2024<SEP>o1 Series"
  },
  "Large Reasoning Models<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219041,
    "update_time": 1765219041,
    "_id": "Large Reasoning Models<SEP>Reinforcement Learning"
  },
  "KL-Divergence Constraints<SEP>Reference Policy": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219041,
    "update_time": 1765219041,
    "_id": "KL-Divergence Constraints<SEP>Reference Policy"
  },
  "Scaling Train-Time RL<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Scaling Train-Time RL<SEP>o1 Series"
  },
  "Frontier Models<SEP>Large Reasoning Models": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Frontier Models<SEP>Large Reasoning Models"
  },
  "Scaling Test-Time Compute<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Scaling Test-Time Compute<SEP>o1 Series"
  },
  "DeepSeek<SEP>R1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "DeepSeek<SEP>R1"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Large Reasoning Models": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e",
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 2,
    "update_time": 1765219262,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Large Reasoning Models"
  },
  "Frontier Models<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Frontier Models<SEP>Reinforcement Learning"
  },
  "Mathematics Benchmarks<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Mathematics Benchmarks<SEP>o1 Series"
  },
  "Guo et al., 2025a<SEP>R1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Guo et al., 2025a<SEP>R1"
  },
  "Reinforcement Learning<SEP>Zero RL": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Reinforcement Learning<SEP>Zero RL"
  },
  "Coding Benchmarks<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Coding Benchmarks<SEP>o1 Series"
  },
  "Anthropic<SEP>Claude-3.7-Sonnet": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Anthropic<SEP>Claude-3.7-Sonnet"
  },
  "Science Benchmarks<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Science Benchmarks<SEP>o1 Series"
  },
  "Comanici et al., 2025<SEP>Gemini 2.0": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Comanici et al., 2025<SEP>Gemini 2.0"
  },
  "Anthropic, 2025a<SEP>Claude-3.7-Sonnet": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Anthropic, 2025a<SEP>Claude-3.7-Sonnet"
  },
  "Claude-3.7-Sonnet<SEP>Hybrid Reasoning": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Claude-3.7-Sonnet<SEP>Hybrid Reasoning"
  },
  "Gemini 2.0<SEP>Longer Context Lengths": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Gemini 2.0<SEP>Longer Context Lengths"
  },
  "Comanici et al., 2025<SEP>Gemini 2.5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Comanici et al., 2025<SEP>Gemini 2.5"
  },
  "R1<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "R1<SEP>o1 Series"
  },
  "Seed et al., 2025b<SEP>Seed-Thinking 1.5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Seed et al., 2025b<SEP>Seed-Thinking 1.5"
  },
  "OpenAI<SEP>o3 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "OpenAI<SEP>o3 Series"
  },
  "Gemini 2.5<SEP>Longer Context Lengths": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Gemini 2.5<SEP>Longer Context Lengths"
  },
  "Generalization Across Domains<SEP>Seed-Thinking 1.5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Generalization Across Domains<SEP>Seed-Thinking 1.5"
  },
  "Multi-Stage Training Pipeline<SEP>R1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Multi-Stage Training Pipeline<SEP>R1"
  },
  "OpenAI, 2025b<SEP>o3 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "OpenAI, 2025b<SEP>o3 Series"
  },
  "OpenAI<SEP>gpt-oss-120b": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "OpenAI<SEP>gpt-oss-120b"
  },
  "R1<SEP>Zero RL": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "R1<SEP>Zero RL"
  },
  "Advanced Reasoning Abilities<SEP>o3 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Advanced Reasoning Abilities<SEP>o3 Series"
  },
  "Agarwal et al., 2025a<SEP>gpt-oss-120b": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Agarwal et al., 2025a<SEP>gpt-oss-120b"
  },
  "GPT5<SEP>OpenAI": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "GPT5<SEP>OpenAI"
  },
  "QwQ-32B<SEP>Qwen Team": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "QwQ-32B<SEP>Qwen Team"
  },
  "GPT5<SEP>OpenAI, 2025a": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "GPT5<SEP>OpenAI, 2025a"
  },
  "Qwen3 Series<SEP>Yang et al., 2025a": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "Qwen3 Series<SEP>Yang et al., 2025a"
  },
  "QwQ-32B<SEP>Team, 2025g": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219042,
    "update_time": 1765219042,
    "_id": "QwQ-32B<SEP>Team, 2025g"
  },
  "Efficient Model<SEP>GPT5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Efficient Model<SEP>GPT5"
  },
  "Benchmark Scores<SEP>Qwen3-235B": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Benchmark Scores<SEP>Qwen3-235B"
  },
  "QwQ-32B<SEP>R1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "QwQ-32B<SEP>R1"
  },
  "He et al., 2025d<SEP>Skywork-OR1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "He et al., 2025d<SEP>Skywork-OR1"
  },
  "Qwen Team<SEP>Qwen3 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Qwen Team<SEP>Qwen3 Series"
  },
  "GPT-5 Thinking<SEP>GPT5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "GPT-5 Thinking<SEP>GPT5"
  },
  "R1-Distilled Models<SEP>Skywork-OR1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "R1-Distilled Models<SEP>Skywork-OR1"
  },
  "Chen et al., 2025a<SEP>Minimax-M1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Chen et al., 2025a<SEP>Minimax-M1"
  },
  "Qwen3 Series<SEP>Qwen3-235B": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Qwen3 Series<SEP>Qwen3-235B"
  },
  "Bercovich et al., 2025<SEP>Llama-Nemotron-Ultra": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Bercovich et al., 2025<SEP>Llama-Nemotron-Ultra"
  },
  "Hybrid Attention<SEP>Minimax-M1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Hybrid Attention<SEP>Minimax-M1"
  },
  "Scalable RL Training<SEP>Skywork-OR1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Scalable RL Training<SEP>Skywork-OR1"
  },
  "Magistral24B<SEP>Rastogi et al., 2025": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Magistral24B<SEP>Rastogi et al., 2025"
  },
  "Accuracy<SEP>Llama-Nemotron-Ultra": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Accuracy<SEP>Llama-Nemotron-Ultra"
  },
  "Minimax-M1<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Minimax-M1<SEP>Reinforcement Learning"
  },
  "Seed-OSS<SEP>Team, 2025a": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Seed-OSS<SEP>Team, 2025a"
  },
  "Magistral24B<SEP>Reinforcement Learning from Scratch": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Magistral24B<SEP>Reinforcement Learning from Scratch"
  },
  "Efficiency<SEP>Llama-Nemotron-Ultra": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Efficiency<SEP>Llama-Nemotron-Ultra"
  },
  "Agentic Tasks<SEP>Claude Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Agentic Tasks<SEP>Claude Series"
  },
  "Anthropic<SEP>Claude-4.1-Opus": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Anthropic<SEP>Claude-4.1-Opus"
  },
  "Long-Context Reasoning Abilities<SEP>Seed-OSS": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Long-Context Reasoning Abilities<SEP>Seed-OSS"
  },
  "Distillation from Prior Models<SEP>Magistral24B": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Distillation from Prior Models<SEP>Magistral24B"
  },
  "Jimenez et al., 2023<SEP>SWE-bench": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Jimenez et al., 2023<SEP>SWE-bench"
  },
  "Kimi K2<SEP>Team, 2025d": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Kimi K2<SEP>Team, 2025d"
  },
  "Anthropic, 2025b<SEP>Claude-4.1-Opus": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Anthropic, 2025b<SEP>Claude-4.1-Opus"
  },
  "GLM4.5<SEP>Zeng et al., 2025a": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "GLM4.5<SEP>Zeng et al., 2025a"
  },
  "Agentic Tasks<SEP>Kimi K2": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Agentic Tasks<SEP>Kimi K2"
  },
  "Claude-4.1-Opus<SEP>SWE-bench": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Claude-4.1-Opus<SEP>SWE-bench"
  },
  "DeepSeek-V3.1<SEP>Tool-Use": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "DeepSeek-V3.1<SEP>Tool-Use"
  },
  "Kimi K2<SEP>Large-Scale Agentic Training Data Synthesis": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Kimi K2<SEP>Large-Scale Agentic Training Data Synthesis"
  },
  "Multimodality<SEP>Widespread Adoption of Reasoning Models": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Multimodality<SEP>Widespread Adoption of Reasoning Models"
  },
  "GLM4.5<SEP>Tool-Use": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "GLM4.5<SEP>Tool-Use"
  },
  "General RL Procedure<SEP>Kimi K2": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "General RL Procedure<SEP>Kimi K2"
  },
  "GPT5<SEP>Multimodality": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "GPT5<SEP>Multimodality"
  },
  "Agentic Tasks<SEP>GLM4.5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Agentic Tasks<SEP>GLM4.5"
  },
  "Gemini 2.5<SEP>Text Domain": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Gemini 2.5<SEP>Text Domain"
  },
  "Gemini 2.5<SEP>Images Domain": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Gemini 2.5<SEP>Images Domain"
  },
  "Agentic Tasks<SEP>DeepSeek-V3.1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Agentic Tasks<SEP>DeepSeek-V3.1"
  },
  "Multimodality<SEP>o3 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Multimodality<SEP>o3 Series"
  },
  "Kimi 1.5<SEP>Team, 2025d": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Kimi 1.5<SEP>Team, 2025d"
  },
  "Kimi 1.5<SEP>Multimodal Reasoning": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Kimi 1.5<SEP>Multimodal Reasoning"
  },
  "Claude Series<SEP>Multimodality": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Claude Series<SEP>Multimodality"
  },
  "Gemini 2.5<SEP>Video Domain": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Gemini 2.5<SEP>Video Domain"
  },
  "QVQ<SEP>Qwen Team, 2025": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "QVQ<SEP>Qwen Team, 2025"
  },
  "Gemini Family<SEP>Multimodality": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Gemini Family<SEP>Multimodality"
  },
  "Audio Domain<SEP>Gemini 2.5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Audio Domain<SEP>Gemini 2.5"
  },
  "QVQ<SEP>Visual Reasoning": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "QVQ<SEP>Visual Reasoning"
  },
  "Skywork R1V2<SEP>Wang et al., 2025k": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Skywork R1V2<SEP>Wang et al., 2025k"
  },
  "Kimi 1.5<SEP>Long Context Scaling": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219043,
    "update_time": 1765219043,
    "_id": "Kimi 1.5<SEP>Long Context Scaling"
  },
  "Reinforcement Learning<SEP>Skywork R1V2": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Reinforcement Learning<SEP>Skywork R1V2"
  },
  "Analytical Thinking<SEP>QVQ": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Analytical Thinking<SEP>QVQ"
  },
  "Joint Reasoning Over Text and Vision Domains<SEP>Kimi 1.5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Joint Reasoning Over Text and Vision Domains<SEP>Kimi 1.5"
  },
  "InternVL Series<SEP>InternVL3": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "InternVL Series<SEP>InternVL3"
  },
  "General Abilities<SEP>Skywork R1V2": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "General Abilities<SEP>Skywork R1V2"
  },
  "KL-Divergence Constraints<SEP>Training": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "KL-Divergence Constraints<SEP>Training"
  },
  "InternVL3<SEP>Zhu et al., 2025c": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "InternVL3<SEP>Zhu et al., 2025c"
  },
  "LRMs<SEP>Large Reasoning Models": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "LRMs<SEP>Large Reasoning Models"
  },
  "Hybrid RL<SEP>Skywork R1V2": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Hybrid RL<SEP>Skywork R1V2"
  },
  "KL-Divergence Constraints<SEP>Language Quality": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "KL-Divergence Constraints<SEP>Language Quality"
  },
  "Reasoning Abilities<SEP>o1 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Reasoning Abilities<SEP>o1 Series"
  },
  "Agentic LRMs<SEP>Large Reasoning Models": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Agentic LRMs<SEP>Large Reasoning Models"
  },
  "Data Mixtures<SEP>Skywork-OR1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Data Mixtures<SEP>Skywork-OR1"
  },
  "Hybrid RL<SEP>MPO": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Hybrid RL<SEP>MPO"
  },
  "Kimi K2<SEP>Non-Verifiable Rewards": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Kimi K2<SEP>Non-Verifiable Rewards"
  },
  "Algorithmic Innovations<SEP>Skywork-OR1": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Algorithmic Innovations<SEP>Skywork-OR1"
  },
  "AI System<SEP>GPT5": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "AI System<SEP>GPT5"
  },
  "Large Reasoning Models<SEP>Multimodal LRMs": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Large Reasoning Models<SEP>Multimodal LRMs"
  },
  "Qwen Family<SEP>Qwen Team": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Qwen Family<SEP>Qwen Team"
  },
  "GRPO<SEP>Hybrid RL": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "GRPO<SEP>Hybrid RL"
  },
  "AI System<SEP>OpenAI": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "AI System<SEP>OpenAI"
  },
  "QwQ-32B<SEP>Qwen Family": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "QwQ-32B<SEP>Qwen Family"
  },
  "Qwen Family<SEP>Qwen3 Series": {
    "chunk_ids": [
      "chunk-37f12102e8df23d0bf48e221b1e75d9e"
    ],
    "count": 1,
    "create_time": 1765219044,
    "update_time": 1765219044,
    "_id": "Qwen Family<SEP>Qwen3 Series"
  },
  "Figure 4<SEP>Large Reasoning Models": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Figure 4<SEP>Large Reasoning Models"
  },
  "InternVL3.5<SEP>Wang et al. [2025o]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "InternVL3.5<SEP>Wang et al. [2025o]"
  },
  "Large Reasoning Models<SEP>Table 1": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Large Reasoning Models<SEP>Table 1"
  },
  "Figure 4<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Figure 4<SEP>Reinforcement Learning"
  },
  "InternVL3.5<SEP>Unified Native Multimodal Pretraining Phase": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "InternVL3.5<SEP>Unified Native Multimodal Pretraining Phase"
  },
  "Figure 4<SEP>Language Models": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Figure 4<SEP>Language Models"
  },
  "Bai et al. [2025]<SEP>Intern-S1": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Bai et al. [2025]<SEP>Intern-S1"
  },
  "InternVL3.5<SEP>Two-Stage Cascade RL Framework": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "InternVL3.5<SEP>Two-Stage Cascade RL Framework"
  },
  "Intern-S1<SEP>Multimodal Scientific Reasoning": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Intern-S1<SEP>Multimodal Scientific Reasoning"
  },
  "Figure 4<SEP>Multimodal Models": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Figure 4<SEP>Multimodal Models"
  },
  "InternVL3.5<SEP>InternVL3.5 1-241B": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "InternVL3.5<SEP>InternVL3.5 1-241B"
  },
  "Step3<SEP>Wang et al. [2025a]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Step3<SEP>Wang et al. [2025a]"
  },
  "Intern-S1<SEP>Mixture-of-Rewards Design": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Intern-S1<SEP>Mixture-of-Rewards Design"
  },
  "Agentic Models<SEP>Figure 4": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Agentic Models<SEP>Figure 4"
  },
  "Efficient Training<SEP>Step3": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Efficient Training<SEP>Step3"
  },
  "GLM-4.5V<SEP>Team et al. [2025a]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "GLM-4.5V<SEP>Team et al. [2025a]"
  },
  "Intern-S1<SEP>Online RL": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Intern-S1<SEP>Online RL"
  },
  "Minimizing Decoding Costs<SEP>Step3": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Minimizing Decoding Costs<SEP>Step3"
  },
  "Ghasemi et al. [2024]<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Ghasemi et al. [2024]<SEP>Reinforcement Learning"
  },
  "GLM-4.5V<SEP>Visual Multimodal Benchmarks": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "GLM-4.5V<SEP>Visual Multimodal Benchmarks"
  },
  "Huh and Mohapatra [2023]<SEP>Multi-Agent RL": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Huh and Mohapatra [2023]<SEP>Multi-Agent RL"
  },
  "Intern-S 1241B<SEP>Intern-S1": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Intern-S 1241B<SEP>Intern-S1"
  },
  "Self-Play Techniques<SEP>Zhang et al. [2024b]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Self-Play Techniques<SEP>Zhang et al. [2024b]"
  },
  "Hunyuan-TurboS Step 3321B<SEP>Step3": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Hunyuan-TurboS Step 3321B<SEP>Step3"
  },
  "RL in Computer Vision Tasks<SEP>Wu et al. [2025h]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "RL in Computer Vision Tasks<SEP>Wu et al. [2025h]"
  },
  "Chen et al. [2025m]<SEP>Long Chain-of-Thought Reasoning": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Chen et al. [2025m]<SEP>Long Chain-of-Thought Reasoning"
  },
  "GLM-4.5V<SEP>GLM-4.5V 106B": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "GLM-4.5V<SEP>GLM-4.5V 106B"
  },
  "Adaptive Behaviors<SEP>Feng et al. [2025c]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Adaptive Behaviors<SEP>Feng et al. [2025c]"
  },
  "LLM Architectures<SEP>Zhao et al. [2023a]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "LLM Architectures<SEP>Zhao et al. [2023a]"
  },
  "Li et al. [2025w]<SEP>Long Chain-of-Thought Reasoning": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Li et al. [2025w]<SEP>Long Chain-of-Thought Reasoning"
  },
  "Adaptive Behaviors<SEP>Sui et al. [2025]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Adaptive Behaviors<SEP>Sui et al. [2025]"
  },
  "DeepSeek-R1<SEP>Zhang et al. [2025a]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "DeepSeek-R1<SEP>Zhang et al. [2025a]"
  },
  "Long Chain-of-Thought Reasoning<SEP>Xia et al. [2024]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Long Chain-of-Thought Reasoning<SEP>Xia et al. [2024]"
  },
  "LLMs<SEP>Zhao et al. [2023a]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "LLMs<SEP>Zhao et al. [2023a]"
  },
  "Li et al. [2025w]<SEP>System 1 Reasoning": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Li et al. [2025w]<SEP>System 1 Reasoning"
  },
  "DeepSeek-R1<SEP>DeepSeek-R1 671B": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "DeepSeek-R1<SEP>DeepSeek-R1 671B"
  },
  "LLMs<SEP>Long Chain-of-Thought Reasoning": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "LLMs<SEP>Long Chain-of-Thought Reasoning"
  },
  "DeepSeek-R1<SEP>DeepSeek-R1-0528 671B": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "DeepSeek-R1<SEP>DeepSeek-R1-0528 671B"
  },
  "Reasoning via Foundation Models<SEP>Sun et al. [2025b]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Reasoning via Foundation Models<SEP>Sun et al. [2025b]"
  },
  "Li et al. [2025w]<SEP>System 2 Reasoning": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Li et al. [2025w]<SEP>System 2 Reasoning"
  },
  "Adaptive Behaviors<SEP>LLMs": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Adaptive Behaviors<SEP>LLMs"
  },
  "Reasoning LLMs<SEP>Zhang et al. [2025a]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Reasoning LLMs<SEP>Zhang et al. [2025a]"
  },
  "Large Reasoning Models<SEP>Sun et al. [2025b]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Large Reasoning Models<SEP>Sun et al. [2025b]"
  },
  "RLHF<SEP>Reasoning LLMs": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "RLHF<SEP>Reasoning LLMs"
  },
  "Gemini 2.5 Flash<SEP>Gemini 2.5 Pro": {
    "chunk_ids": [
      "chunk-519d56991b1bbd2046e61bcd26303d2e"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Gemini 2.5 Flash<SEP>Gemini 2.5 Pro"
  },
  "21/117B<SEP>GLM-4.5V 106B": {
    "chunk_ids": [
      "chunk-519d56991b1bbd2046e61bcd26303d2e"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "21/117B<SEP>GLM-4.5V 106B"
  },
  "Foundation Models<SEP>Sun et al. [2025b]": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Foundation Models<SEP>Sun et al. [2025b]"
  },
  "Gemini 2.5 Pro<SEP>Seed-Thinking 1.6": {
    "chunk_ids": [
      "chunk-519d56991b1bbd2046e61bcd26303d2e"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Gemini 2.5 Pro<SEP>Seed-Thinking 1.6"
  },
  "Gemini 2.5 Flash<SEP>O3-Pro": {
    "chunk_ids": [
      "chunk-519d56991b1bbd2046e61bcd26303d2e"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "Gemini 2.5 Flash<SEP>O3-Pro"
  },
  "RLVR<SEP>Reasoning LLMs": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "RLVR<SEP>Reasoning LLMs"
  },
  "LLMs<SEP>RLHF": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219166,
    "update_time": 1765219166,
    "_id": "LLMs<SEP>RLHF"
  },
  "O3-Pro<SEP>Seed-Thinking 1.6": {
    "chunk_ids": [
      "chunk-519d56991b1bbd2046e61bcd26303d2e"
    ],
    "count": 1,
    "create_time": 1765219167,
    "update_time": 1765219167,
    "_id": "O3-Pro<SEP>Seed-Thinking 1.6"
  },
  "LLMs<SEP>RLVR": {
    "chunk_ids": [
      "chunk-aa95a088a3c7d1c923aa324fd7c02a63"
    ],
    "count": 1,
    "create_time": 1765219167,
    "update_time": 1765219167,
    "_id": "LLMs<SEP>RLVR"
  },
  "Gemini 2.5 Flash<SEP>Seed-Thinking 1.6": {
    "chunk_ids": [
      "chunk-519d56991b1bbd2046e61bcd26303d2e"
    ],
    "count": 1,
    "create_time": 1765219167,
    "update_time": 1765219167,
    "_id": "Gemini 2.5 Flash<SEP>Seed-Thinking 1.6"
  },
  "Gemini 2.5 Pro<SEP>O3-Pro": {
    "chunk_ids": [
      "chunk-519d56991b1bbd2046e61bcd26303d2e"
    ],
    "count": 1,
    "create_time": 1765219167,
    "update_time": 1765219167,
    "_id": "Gemini 2.5 Pro<SEP>O3-Pro"
  },
  "Open-Source Models<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "Open-Source Models<SEP>Reinforcement Learning"
  },
  "DeepSeek<SEP>DeepSeek-R1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "DeepSeek<SEP>DeepSeek-R1"
  },
  "Online Policy Mirror Descent<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "Online Policy Mirror Descent<SEP>Reinforcement Learning"
  },
  "DeepSeek-R1<SEP>Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "DeepSeek-R1<SEP>Mixture of Experts"
  },
  "Mixed Preference Optimization<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "Mixed Preference Optimization<SEP>Reinforcement Learning"
  },
  "DeepSeek-R1<SEP>Multi-Layer Attention": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "DeepSeek-R1<SEP>Multi-Layer Attention"
  },
  "Clipped IS-weight Policy Optimization<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "Clipped IS-weight Policy Optimization<SEP>Reinforcement Learning"
  },
  "ORZ<SEP>StepAI": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "ORZ<SEP>StepAI"
  },
  "GRPO<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "GRPO<SEP>Reinforcement Learning"
  },
  "Dense Architecture<SEP>ORZ": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "Dense Architecture<SEP>ORZ"
  },
  "PPO<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "PPO<SEP>Reinforcement Learning"
  },
  "DeepSeek-R1<SEP>GRPO": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "DeepSeek-R1<SEP>GRPO"
  },
  "GSPO<SEP>Reinforcement Learning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "GSPO<SEP>Reinforcement Learning"
  },
  "ORZ<SEP>PPO": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "ORZ<SEP>PPO"
  },
  "AlibabaQwen<SEP>QwQ": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "AlibabaQwen<SEP>QwQ"
  },
  "DeepSeek-R1<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219259,
    "update_time": 1765219259,
    "_id": "DeepSeek-R1<SEP>Text Modality"
  },
  "Dense Architecture<SEP>QwQ": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>QwQ"
  },
  "Microsoft<SEP>Phi-4Reasoning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Microsoft<SEP>Phi-4Reasoning"
  },
  "ORZ<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "ORZ<SEP>Text Modality"
  },
  "Dense Architecture<SEP>Phi-4Reasoning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>Phi-4Reasoning"
  },
  "QwQ<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "QwQ<SEP>Text Modality"
  },
  "GRPO<SEP>Phi-4Reasoning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "GRPO<SEP>Phi-4Reasoning"
  },
  "Skywork<SEP>Skywork-R1V2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Skywork<SEP>Skywork-R1V2"
  },
  "Open-Source Models<SEP>QwQ": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Open-Source Models<SEP>QwQ"
  },
  "Phi-4Reasoning<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Phi-4Reasoning<SEP>Text Modality"
  },
  "Dense Architecture<SEP>Skywork-R1V2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>Skywork-R1V2"
  },
  "DeepSeek-R1<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "DeepSeek-R1<SEP>Open-Source Models"
  },
  "ORZ<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "ORZ<SEP>Open-Source Models"
  },
  "Mixed Preference Optimization<SEP>Skywork-R1V2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Mixed Preference Optimization<SEP>Skywork-R1V2"
  },
  "InternVL3<SEP>ShanghaiAILab": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "InternVL3<SEP>ShanghaiAILab"
  },
  "Dense Architecture<SEP>InternVL3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>InternVL3"
  },
  "GRPO<SEP>Skywork-R1V2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "GRPO<SEP>Skywork-R1V2"
  },
  "Open-Source Models<SEP>Phi-4Reasoning": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Open-Source Models<SEP>Phi-4Reasoning"
  },
  "InternVL3<SEP>Mixed Preference Optimization": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "InternVL3<SEP>Mixed Preference Optimization"
  },
  "Skywork-R1V2<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Skywork-R1V2<SEP>Text Modality"
  },
  "MiMo<SEP>Xiaomi": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "MiMo<SEP>Xiaomi"
  },
  "InternVL3<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "InternVL3<SEP>Text Modality"
  },
  "Image Modality<SEP>Skywork-R1V2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Image Modality<SEP>Skywork-R1V2"
  },
  "Dense Architecture<SEP>MiMo": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>MiMo"
  },
  "Open-Source Models<SEP>Skywork-R1V2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Open-Source Models<SEP>Skywork-R1V2"
  },
  "InternVL3<SEP>Video Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "InternVL3<SEP>Video Modality"
  },
  "GRPO<SEP>MiMo": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "GRPO<SEP>MiMo"
  },
  "AlibabaQwen<SEP>Qwen3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "AlibabaQwen<SEP>Qwen3"
  },
  "InternVL3<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "InternVL3<SEP>Open-Source Models"
  },
  "MiMo<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "MiMo<SEP>Text Modality"
  },
  "Mixture of Experts<SEP>Qwen3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Mixture of Experts<SEP>Qwen3"
  },
  "Image Modality<SEP>InternVL3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Image Modality<SEP>InternVL3"
  },
  "Dense Architecture<SEP>Qwen3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>Qwen3"
  },
  "Llama-Nemotron-Ultra<SEP>NVIDIA": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Llama-Nemotron-Ultra<SEP>NVIDIA"
  },
  "GRPO<SEP>Qwen3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "GRPO<SEP>Qwen3"
  },
  "Dense Architecture<SEP>Llama-Nemotron-Ultra": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>Llama-Nemotron-Ultra"
  },
  "Qwen3<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Qwen3<SEP>Text Modality"
  },
  "INTELLECT-2<SEP>IntellectAI": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "INTELLECT-2<SEP>IntellectAI"
  },
  "Llama-Nemotron-Ultra<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Llama-Nemotron-Ultra<SEP>Text Modality"
  },
  "Open-Source Models<SEP>Qwen3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Open-Source Models<SEP>Qwen3"
  },
  "Dense Architecture<SEP>INTELLECT-2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>INTELLECT-2"
  },
  "MiMo<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "MiMo<SEP>Open-Source Models"
  },
  "Hunyuan-TurboS<SEP>Tencent": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Hunyuan-TurboS<SEP>Tencent"
  },
  "INTELLECT-2<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "INTELLECT-2<SEP>Text Modality"
  },
  "Hunyuan-TurboS<SEP>Hybrid Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Hunyuan-TurboS<SEP>Hybrid Mixture of Experts"
  },
  "Llama-Nemotron-Ultra<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Llama-Nemotron-Ultra<SEP>Open-Source Models"
  },
  "Hunyuan-TurboS<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Hunyuan-TurboS<SEP>Text Modality"
  },
  "Skywork<SEP>SkyworkOR-1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Skywork<SEP>SkyworkOR-1"
  },
  "INTELLECT-2<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "INTELLECT-2<SEP>Open-Source Models"
  },
  "GRPO<SEP>Llama-Nemotron-Ultra": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "GRPO<SEP>Llama-Nemotron-Ultra"
  },
  "Dense Architecture<SEP>SkyworkOR-1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Dense Architecture<SEP>SkyworkOR-1"
  },
  "Hunyuan-TurboS<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "Hunyuan-TurboS<SEP>Open-Source Models"
  },
  "GRPO<SEP>INTELLECT-2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "GRPO<SEP>INTELLECT-2"
  },
  "DeepSeek<SEP>DeepSeek-R1-0528": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219260,
    "update_time": 1765219260,
    "_id": "DeepSeek<SEP>DeepSeek-R1-0528"
  },
  "SkyworkOR-1<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "SkyworkOR-1<SEP>Text Modality"
  },
  "GRPO<SEP>Hunyuan-TurboS": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GRPO<SEP>Hunyuan-TurboS"
  },
  "DeepSeek-R1-0528<SEP>Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "DeepSeek-R1-0528<SEP>Mixture of Experts"
  },
  "Open-Source Models<SEP>SkyworkOR-1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Open-Source Models<SEP>SkyworkOR-1"
  },
  "Magistral<SEP>MistralAI": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Magistral<SEP>MistralAI"
  },
  "DeepSeek-R1-0528<SEP>Multi-Layer Attention": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "DeepSeek-R1-0528<SEP>Multi-Layer Attention"
  },
  "GRPO<SEP>SkyworkOR-1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GRPO<SEP>SkyworkOR-1"
  },
  "Dense Architecture<SEP>Magistral": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Dense Architecture<SEP>Magistral"
  },
  "Minimax<SEP>Minimax-M1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Minimax<SEP>Minimax-M1"
  },
  "Magistral<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Magistral<SEP>Text Modality"
  },
  "Hybrid Mixture of Experts<SEP>Minimax-M1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Hybrid Mixture of Experts<SEP>Minimax-M1"
  },
  "Magistral<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Magistral<SEP>Open-Source Models"
  },
  "Clipped IS-weight Policy Optimization<SEP>Minimax-M1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Clipped IS-weight Policy Optimization<SEP>Minimax-M1"
  },
  "GRPO<SEP>Magistral": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GRPO<SEP>Magistral"
  },
  "Intern-S1<SEP>ShanghaiAILab": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Intern-S1<SEP>ShanghaiAILab"
  },
  "Minimax-M1<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Minimax-M1<SEP>Text Modality"
  },
  "DeepSeek-R1-0528<SEP>GRPO": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "DeepSeek-R1-0528<SEP>GRPO"
  },
  "Intern-S1<SEP>Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Intern-S1<SEP>Mixture of Experts"
  },
  "Minimax-M1<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Minimax-M1<SEP>Open-Source Models"
  },
  "DeepSeek-R1-0528<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "DeepSeek-R1-0528<SEP>Text Modality"
  },
  "Kimi<SEP>KimiK2": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Kimi<SEP>KimiK2"
  },
  "Intern-S1<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Intern-S1<SEP>Text Modality"
  },
  "DeepSeek-R1-0528<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "DeepSeek-R1-0528<SEP>Open-Source Models"
  },
  "KimiK2<SEP>Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "KimiK2<SEP>Mixture of Experts"
  },
  "Image Modality<SEP>Intern-S1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Image Modality<SEP>Intern-S1"
  },
  "KimiK2<SEP>Online Policy Mirror Descent": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "KimiK2<SEP>Online Policy Mirror Descent"
  },
  "Step3<SEP>StepAI": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Step3<SEP>StepAI"
  },
  "GRPO<SEP>Intern-S1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GRPO<SEP>Intern-S1"
  },
  "KimiK2<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "KimiK2<SEP>Text Modality"
  },
  "Mixture of Experts<SEP>Step3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Mixture of Experts<SEP>Step3"
  },
  "Intern-S1<SEP>Video Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Intern-S1<SEP>Video Modality"
  },
  "KimiK2<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "KimiK2<SEP>Open-Source Models"
  },
  "Step3<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Step3<SEP>Text Modality"
  },
  "AlibabaQwen<SEP>Qwen3-2507": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "AlibabaQwen<SEP>Qwen3-2507"
  },
  "Mixture of Experts<SEP>Qwen3-2507": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Mixture of Experts<SEP>Qwen3-2507"
  },
  "Image Modality<SEP>Step3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Image Modality<SEP>Step3"
  },
  "Dense Architecture<SEP>Qwen3-2507": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Dense Architecture<SEP>Qwen3-2507"
  },
  "Step3<SEP>Video Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Step3<SEP>Video Modality"
  },
  "GLM-4.1V-Thinking<SEP>ZhipuAI": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.1V-Thinking<SEP>ZhipuAI"
  },
  "GSPO<SEP>Qwen3-2507": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GSPO<SEP>Qwen3-2507"
  },
  "Open-Source Models<SEP>Step3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Open-Source Models<SEP>Step3"
  },
  "Dense Architecture<SEP>GLM-4.1V-Thinking": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Dense Architecture<SEP>GLM-4.1V-Thinking"
  },
  "Qwen3-2507<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Qwen3-2507<SEP>Text Modality"
  },
  "Intern-S1<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Intern-S1<SEP>Open-Source Models"
  },
  "GLM-4.1V-Thinking<SEP>GRPO": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.1V-Thinking<SEP>GRPO"
  },
  "GLM-4.5<SEP>ZhipuAI": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.5<SEP>ZhipuAI"
  },
  "GLM-4.1V-Thinking<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.1V-Thinking<SEP>Text Modality"
  },
  "Open-Source Models<SEP>Qwen3-2507": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Open-Source Models<SEP>Qwen3-2507"
  },
  "GLM-4.5<SEP>Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.5<SEP>Mixture of Experts"
  },
  "GLM-4.1V-Thinking<SEP>Image Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.1V-Thinking<SEP>Image Modality"
  },
  "Skywork<SEP>Skywork-R1V3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Skywork<SEP>Skywork-R1V3"
  },
  "GLM-4.5<SEP>GRPO": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.5<SEP>GRPO"
  },
  "GLM-4.1V-Thinking<SEP>Video Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.1V-Thinking<SEP>Video Modality"
  },
  "Dense Architecture<SEP>Skywork-R1V3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Dense Architecture<SEP>Skywork-R1V3"
  },
  "GLM-4.5<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.5<SEP>Text Modality"
  },
  "GLM-4.1V-Thinking<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "GLM-4.1V-Thinking<SEP>Open-Source Models"
  },
  "OpenAI<SEP>gpt-oss": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "OpenAI<SEP>gpt-oss"
  },
  "Skywork-R1V3<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219261,
    "update_time": 1765219261,
    "_id": "Skywork-R1V3<SEP>Text Modality"
  },
  "Mixture of Experts<SEP>gpt-oss": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Mixture of Experts<SEP>gpt-oss"
  },
  "GRPO<SEP>Skywork-R1V3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GRPO<SEP>Skywork-R1V3"
  },
  "BytedanceSeed<SEP>Seed-OSS": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "BytedanceSeed<SEP>Seed-OSS"
  },
  "Text Modality<SEP>gpt-oss": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Text Modality<SEP>gpt-oss"
  },
  "Image Modality<SEP>Skywork-R1V3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Image Modality<SEP>Skywork-R1V3"
  },
  "Dense Architecture<SEP>Seed-OSS": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Dense Architecture<SEP>Seed-OSS"
  },
  "GLM-4.5V<SEP>ZhipuAI": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GLM-4.5V<SEP>ZhipuAI"
  },
  "Open-Source Models<SEP>Skywork-R1V3": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Open-Source Models<SEP>Skywork-R1V3"
  },
  "Seed-OSS<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Seed-OSS<SEP>Text Modality"
  },
  "GLM-4.5V<SEP>Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GLM-4.5V<SEP>Mixture of Experts"
  },
  "GLM-4.5<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GLM-4.5<SEP>Open-Source Models"
  },
  "GLM-4.5V<SEP>GRPO": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GLM-4.5V<SEP>GRPO"
  },
  "Open-Source Models<SEP>gpt-oss": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Open-Source Models<SEP>gpt-oss"
  },
  "InternVL3.5<SEP>ShanghaiAILab": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "InternVL3.5<SEP>ShanghaiAILab"
  },
  "GLM-4.5V<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GLM-4.5V<SEP>Text Modality"
  },
  "InternVL3.5<SEP>Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "InternVL3.5<SEP>Mixture of Experts"
  },
  "Open-Source Models<SEP>Seed-OSS": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Open-Source Models<SEP>Seed-OSS"
  },
  "GLM-4.5V<SEP>Image Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GLM-4.5V<SEP>Image Modality"
  },
  "Dense Architecture<SEP>InternVL3.5": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Dense Architecture<SEP>InternVL3.5"
  },
  "GLM-4.5V<SEP>Video Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GLM-4.5V<SEP>Video Modality"
  },
  "InternVL3.5<SEP>Mixed Preference Optimization": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "InternVL3.5<SEP>Mixed Preference Optimization"
  },
  "GLM-4.5V<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GLM-4.5V<SEP>Open-Source Models"
  },
  "Baidu<SEP>ERNIE-4.5-Thinking": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Baidu<SEP>ERNIE-4.5-Thinking"
  },
  "GSPO<SEP>InternVL3.5": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "GSPO<SEP>InternVL3.5"
  },
  "ERNIE-4.5-Thinking<SEP>Mixture of Experts": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "ERNIE-4.5-Thinking<SEP>Mixture of Experts"
  },
  "InternVL3.5<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "InternVL3.5<SEP>Text Modality"
  },
  "ERNIE-4.5-Thinking<SEP>Text Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "ERNIE-4.5-Thinking<SEP>Text Modality"
  },
  "Image Modality<SEP>InternVL3.5": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Image Modality<SEP>InternVL3.5"
  },
  "Open-Source Models<SEP>Table 1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "Open-Source Models<SEP>Table 1"
  },
  "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Table 1": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "A Survey of Reinforcement Learning for Large Reasoning Models<SEP>Table 1"
  },
  "ERNIE-4.5-Thinking<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "ERNIE-4.5-Thinking<SEP>Open-Source Models"
  },
  "InternVL3.5<SEP>Video Modality": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "InternVL3.5<SEP>Video Modality"
  },
  "InternVL3.5<SEP>Open-Source Models": {
    "chunk_ids": [
      "chunk-9f6704aa27cd8e9483d9f72f2cf4c3fe"
    ],
    "count": 1,
    "create_time": 1765219262,
    "update_time": 1765219262,
    "_id": "InternVL3.5<SEP>Open-Source Models"
  }
}